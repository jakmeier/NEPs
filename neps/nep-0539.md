---
NEP: 539
Title: Cross-Shard Congestion Control
Authors: Waclaw Banasik <waclaw@near.org>, Jakob Meier <inbox@jakobmeier.ch>
Status: New
DiscussionsTo: https://github.com/nearprotocol/neps/pull/539
Type: Protocol
Version: 1.0.0
Created: 2024-03-21
LastUpdated: 2024-03-22
---

## Summary

We propose to limit the outgoing receipts included in each chunk. Limits depend
on the congestion level of that receiving shard and are to be enforced by the
protocol.

As the first line of defense, shards must stop accepting more transactions to
memory congested shards, where memory congestion is measured as the memory
consumption for receipts stored in any queue or buffer. This includes the delayed
receipts queue so the incoming congestion is also somewhat reflected in the memory
congestion but with focus on memory rather than gas usage. 

As the second line of defense, shards must hold back already produced receipts
before forwarding them when the receiving shard experiences incoming congestion.
The incoming congestion is measured by the amount of gas attached to receipts in
delayed queue of the receiving shard.

This proposal replaces the local congestion control rules already in place.

## Motivation

We want to guarantee the Near Protocol blockchain operates stable even during
congestion.

Today, when users send transactions at a higher rate than the network can
process them, receipts accumulate without limits. This leads to unlimited memory
consumption on chunk producer's and validator's machines. Furthermore, the delay
for a transaction from when it is accepted to when it finishes execution becomes
larger and larger, as the receipts need to queue behind those already in the
system.

First attempts to limit the memory consumption have been added without protocol
changes. This is known as "local congestion control" and can be summarized in
two rules:

- Limit the transaction pool to 100 MB.
  https://github.com/near/nearcore/pull/9172
- Once we have accumulated more than 20k delayed receipts in a shard,
  chunk-producers for that shard stop accepting more transactions.
  https://github.com/near/nearcore/pull/9222

But this does not put any limits on what shards will accept for other shards.
For example, when a particular contract is popular, the contract's shard will
eventually stop accepting new transactions but all other shards keep accepting
more and more transactions that produce receipts for the popular contract.
Therefore the number of delayed receipts keeps growing indefinitely.

Cross-shard congestion control addresses this issue by stopping new transactions
at the source and delaying receipt forwarding when the receiving shard has
reached its memory limit.

## Specification

The proposal adds fields to chunks headers, it adds a new trie column, it changes
the rules to select transactions, and it changes the chunk execution flow. The
next four sections specify each of these changes in more details.

### Chunk header changes

We change the chunk header to include congestion information.
Specifically, we include two indicators.

```rust
ShardChunkHeaderInnerV3 {
  // ...all fields from ShardChunkHeaderInnerV2
  incoming_congestion: u16,
  memory_congestion: u16,
}
```

This adds 4 bytes to the chunk header, increasing it from 374 bytes to 378
bytes in borsh representation. (Assuming no validator proposals included.)
This in turn increases the block size by 4 bytes per shard.

While the numbers are stored as `u16`, for the remainder of the NEP
specification, `incoming_congestion` and `memory_congestion` values are
interpreted as numbers between 0 and 1, dividing the stored `u16` by `u16::MAX`
(65535).

### Changes to transaction selection

Today, transactions are taken from the chunk producer's pool until `tx_limit` is
reached, where `tx_limit` is computed as follow.

```python
# old
tx_limit = 500 Tgas if len(delayed_receipts) < 20_000 else 0
```

We replace the formula for the transaction limit to depend on the
`incoming_congestion` computed in the previous shard variable (between 0 and 1):

```python
# new
MIN_GAS = 5 Tgas
MAX_GAS = 500 Tgas
tx_limit = mix(MAX_GAS, MIN_GAS, incoming_congestion)
```

This smoothly limits the amount of new work for a shard, based on how much work
is already queued up.

*TODO: fine-tune `MIN_GAS` and `MAX_GAS`*

In the pseudo code above, we borrow the [`mix`](https://docs.gl/sl4/mix)
function from GLSL for linear interpolation.

> `mix(x, y, a)`
> 
> `mix` performs a linear interpolation between x and y using a to weight between
> them. The return value is computed as $x \times (1 - a) + y \times a$. 


Plus, we add the additional rule to reject all transactions to shard with an
`memory_congestion` above a certain threshold.

```python
def filter_tx(tx):
  MEMORY_CONGESTION_THRESHOLD = 0.5
  if memory_congestion(tx.receiver_shard_id) > MEMORY_CONGESTION_THRESHOLD
    tx.reject()
  else
    tx.accept()
```

This stops (some) new incoming work at the source for when a shard is using too
much memory to store unprocessed receipts.

TODO: fine-tune `MEMORY_CONGESTION_THRESHOLD`

Chunk validators must validate that the two rules above are respected in a
produced chunk.

TODO: We probably need something extra to guarantee limited queue sizes. See
this comment https://github.com/near/NEPs/pull/539#issuecomment-2022132060.


### Changes to chunk execution

We add 3 new steps to chunk execution (enumerate as 1, 2, 6 below) and modify
how outgoing receipts are treated in the transaction conversion step (3) and in
the receipts execution step (4).

The new chunk execution then follows this order.

1. (new) Compute bandwidth limits to other shards based on the congestion information.
   The formula is:
    ```python
        # linear interpolation based on congestion level
        outgoing_gas_limit[receiver]
          = mix(30 Pgas, 0 Pgas, incoming_congestion(receiver))
    ```
2. (new) Drain receipts in the outgoing buffer from the previous round-
    - Subtract `receipt.gas()` from `outgoing_gas_limit[receipt.receiver]` for
      each receipt drained.
    - Keep receipts in the buffer if the gas limit would be negative.
    - Add the removed receipts to the outgoing receipts of the new chunk.
3. Convert all transactions to receipts included in the chunk.
    - Local receipts, which are receipts where the sender account id is equal to
      the receiver id, are set aside as local receipts for step 4.
    - Non-local receipts up to `outgoing_gas_limit[receipt.receiver]` for the
      respective shard go to the outgoing receipts list of the chunk.
    - (new) Non-local receipts above `outgoing_gas_limit[receipt.receiver]` for
      the respective shard go to the outgoing receipts buffer.
4. Execute receipts in the order of `local`, `delayed`, `incoming`.
    - Don't stop before all receipts are executed or more than 1000 Tgas have
      been burnt. Burnt gas includes the burnt gas from step 3.
    - Outgoing receipts up to what is left in
      `outgoing_gas_limit[receipt.receiver]` per shard (after step 3) go to the
      outgoing receipts list of the chunk.
    - (new) Outgoing receipts above `outgoing_gas_limit[receipt.receiver]`
      go to the outgoing receipts buffer.
5. Remaining local or incoming receipts are added to the end of the `delayed`
   receipts queue.
6. (new) Compute own congestion information for the next block.:

    ```python
    MAX_CONGESTION_INCOMING_GAS = 100 PGas
    gas_backlog = sum([receipt.gas() for receipt in delayed_receipts_queue])
    incoming_congestion = gas_backlog / MAX_CONGESTION_INCOMING_GAS
    incoming_congestion = min(1.0, incoming_congestion)

    MAX_CONGESTION_MEMORY_CONSUMPTION = 500 MB
    memory_consumption = 0
    memory_consumption += sum([receipt.size() for receipt in delayed_receipts_queue])
    memory_consumption += sum([receipt.size() for receipt in postponed_receipts_queue])
    memory_consumption += sum([receipt.size() for receipt in outgoing_receipts_buffer])
  
    memory_congestion = memory_consumption / MAX_CONGESTION_MEMORY_CONSUMPTION
    memory_congestion = min(1.0, memory_congestion)
    ```

*TODO: fine-tune `MAX_CONGESTION_INCOMING_GAS` and `MAX_CONGESTION_MEMORY_CONSUMPTION`*

In the formula above, the receipt gas and the receipt size are defined as:

```python
def gas(receipt):
  return receipt.attached_gas + receipt.exec_gas

def size(receipt):
  return len(borsh(receipt))
```

### Change to Trie

We store the outgoing buffered receipts in the trie, similar to delayed receipts
but in their own separate column. But instead of a single queue per shard, we add
one queue for each other shard at the current sharding layout.

We add two trie columns:

* `BUFFERED_RECEIPT_INDICES: u8 = 13;`
* `BUFFERED_RECEIPT: u8 = 14`

The `BUFFERED_RECEIPT_INDICES` column only has one value, which stores a borsh-serialized instance of
`BufferedReceiptIndices` defines as follows:

```rust
pub struct BufferedReceiptIndices {
    pub shard_buffer_indices: BTreeMap<ShardId, ShardBufferedReceiptIndices>,
}

pub struct ShardBufferedReceiptIndices {
    // First inclusive index in the queue.
    pub first_index: u64,
    // Exclusive end index of the queue
    pub next_available_index: u64,
}
```

The `BUFFERED_RECEIPT` column stores receipts keyed by 
`TrieKey::BufferedReceipt{ receiving_shard: ShardId, index: u64 }`.

The `BufferedReceiptIndices` map defines which queues exist, which changes
during resharding. For each existing queue, all receipts in the range
`[first_index, next_available_index)` (inclusive start, exclusive end) must
exist under the key with the corresponding shard.

## Reference Implementation

A reference implementation is available in this PR against nearcore:
https://github.com/near/nearcore/pull/10918

Here are the most important details which are not already described in the
specification above but are defined in the reference implementation.

### Changes to Chunk Extra

After applying a chunk, we store detailed information of the shard in the chunk
extra. Unlike the shard header, this is only stored on the shard and not shared
globally. Therefore, we propose to store a less compressed representation of the
congestion information and only reduce it to the two numbers for the chunk header.

The new fields in the chunk extra are included in `ChunkExtraV3`.

```rust
pub struct ChunkExtraV3 {

    // ...all fields from ChunkExtraV2

    /// Statistics on stored receipts, used to compute the congestion level.
    pub stored_receipts_info: StoredReceiptsInfo,
}

/// Detailed information about receipts currently stored in the trie,
/// potentially contributing to congestion.
///
/// This data is stored in the [`ChunkExtra`], therefore changing its layout
/// requires a protocol change.
pub struct StoredReceiptsInfo {
    /// Action execution gas plus attached gas of all receipts in the delayed
    /// receipts queue.
    pub delayed_receipts_gas: Gas,
    /// Size of borsh serialized receipts in the delayed receipts queue.
    pub delayed_receipts_bytes: u64,
    /// Size of borsh serialized postponed receipts.
    pub postponed_receipts_bytes: u64,
    /// Size of borsh serialized receipts in the outgoing buffer.
    pub buffered_receipts_bytes: u64,
}
```

The two numbers for the chunk header are derived as follows:

```rust
let gas = delayed_receipts_guaranteed_burnt_gas + delayed_receipts_attached_gas;
let memory = delayed_receipts_bytes + postponed_receipts_bytes + buffered_receipts_bytes;

let incoming_congestion: u16_fraction(gas_backlog, MAX_CONGESTION_INCOMING_GAS);
let memory_congestion: u16_fraction(memory, MAX_CONGESTION_MEMORY_CONSUMPTION);

fn u16_fraction(value: u64, max: u64) -> u16 {
    let bounded_value = std::cmp::min(value, max);
    (bounded_value as u128 * u16::MAX as u128 / max as u128) as u16
}
```

This implementation allows to efficiently update the `StoredReceiptsInfo` during
chunk application by starting with the information of the previous chunk and
applying only the changes. A less efficient alternative would require iterating
all delayed and buffered receipts every chunk to compute the current congestion
information.


### Bootstrapping

The previous section explain how the gas and bytes information of unprocessed
receipts is computed based on what it was for the previous chunk. But for the
first chunk with this feature enabled, the information for the previous chunk is
not available.

In this specific case, we detect that the previous information is not available
and therefore we trigger an iteration of the existing queues to compute the
correct values.

This computed `StoredReceiptsInfo` only applies locally. But the next value of it
will be shared in the chunk header and other shards will start using it to limit
the transactions they accept and receipts they forward.

The congestion info of other shards is assumed to be `incoming_congestion = 0`
and `memory_congestion = 0` for the first block with the cross-shard congestion
control feature enabled.

TODO: How to bootstrap new shards after resharding?

TODO: What if there is a resharding happening at the same time as the feature is
enabled?

### Missing Chunks

When a chunk is missing, we suggest to use the congestion information of the
last available chunk header for the shard. In practical terms this simply means
we take the chunk header available in the block, even if the included height is
not the latest.

### Validation  Changes

TODO: explain changes to validation, including but not limited to balance
checker and new header fields validation

## Security Implications

[Explicitly outline any security concerns in relation to the NEP, and potential ways to resolve or mitigate them. At the very least, well-known relevant threats must be covered, e.g. person-in-the-middle, double-spend, XSS, CSRF, etc.]

## Alternatives

TODO (Discussion is still ongoing)

[Explain any alternative designs that were considered and the rationale for not choosing them. Why your design is superior?]

## Future possibilities

While this proposal treats all requests the same, it sets the base for a proper
transaction priority implementation. We co-designed this proposal with
[NEP-541](https://github.com/near/NEPs/pull/541), which adds a transaction
priority fee. On a very high level, the fee is used to auction off a part of the
available gas per chunk to the highest bidders.


TODO: describe how it combines with resharding

TODO: describe how it combines with stateless validation / ApplyChunkResult.applied_receipts_hash


## Consequences

TODO (in general)
TODO: describe if anything changes for light clients

[This section describes the consequences, after applying the decision. All consequences should be summarized here, not just the "positive" ones. Record any concerns raised throughout the NEP discussion.]

### Positive

- p1

### Neutral

- n1

### Negative

- n1

### Backwards Compatibility

TODO

[All NEPs that introduce backwards incompatibilities must include a section describing these incompatibilities and their severity. Author must explain a proposes to deal with these incompatibilities. Submissions without a sufficient backwards compatibility treatise may be rejected outright.]

## Unresolved Issues (Optional)

TODO

[Explain any issues that warrant further discussion. Considerations

- What parts of the design do you expect to resolve through the NEP process before this gets merged?
- What parts of the design do you expect to resolve through the implementation of this feature before stabilization?
- What related issues do you consider out of scope for this NEP that could be addressed in the future independently of the solution that comes out of this NEP?]

## Changelog

[The changelog section provides historical context for how the NEP developed over time. Initial NEP submission should start with version 1.0.0, and all subsequent NEP extensions must follow [Semantic Versioning](https://semver.org/). Every version should have the benefits and concerns raised during the review. The author does not need to fill out this section for the initial draft. Instead, the assigned reviewers (Subject Matter Experts) should create the first version during the first technical review. After the final public call, the author should then finalize the last version of the decision context.]

### 1.0.0 - Initial Version

> Placeholder for the context about when and who approved this NEP version.

#### Benefits

> List of benefits filled by the Subject Matter Experts while reviewing this version:

- Benefit 1
- Benefit 2

#### Concerns

> Template for Subject Matter Experts review for this version:
> Status: New | Ongoing | Resolved

|   # | Concern | Resolution | Status |
| --: | :------ | :--------- | -----: |
|   1 |         |            |        |
|   2 |         |            |        |

## Copyright

Copyright and related rights waived via [CC0](https://creativecommons.org/publicdomain/zero/1.0/).
